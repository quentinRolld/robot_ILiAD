# Robot_ILiAD

[![Python](https://img.shields.io/badge/python-3.10-blue?style=for-the-badge)](https://www.python.org)
[![HF Models](https://img.shields.io/badge/%F0%9F%A4%97-Models-yellow?style=for-the-badge)](https://huggingface.co/openvla/openvla-7b)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.2.0-EE4C2C.svg?style=for-the-badge&logo=pytorch)](https://pytorch.org/get-started/locally/)
[![License](https://img.shields.io/github/license/TRI-ML/prismatic-vlms?style=for-the-badge)](LICENSE)

<hr style="border: 2px solid gray;"></hr>

![alt text](https://medias.spotern.com/spots/w1280/13/13334-1532336916.webp)

**Autonomous robot boosted with openVLA**

The goal of this project is to create a robot capable of interacting with a human and realize an action based on the instruction of the user.

<hr style="border: 2px solid gray;"></hr>

## Sound package :
- **Speech to text**, retrieve user verbal instructions through USB microphone and traducts to text using ...
- **User Text to VLM to response text**, inputs user instruction text to the Llama 7B LLM and retrieve the response 
- **Response text to robot speech**, transform LLM text into audio signal using GTTS, and transmit this signal to a speaker using I2S bus.

## Motor package :

## Vision package :

## OpenVLA package :

<hr style="border: 2px solid gray;"></hr>

